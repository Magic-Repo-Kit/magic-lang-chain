{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开了解LCEL\n",
    "LCEL是LangChain帮助我们快速构建复杂的链式组件的基本语法，并且流处理，并且调用和日志处理都是可以开箱即用的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本案例开始（prompt+context+output parser）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(动态提示词模板+输出) 这个是最常见也是最基本调的用方式，下面我将用获得城市旅游信息作为案例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出模板: input_variables=['topic'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], template='我想去{topic}旅行，我想知道这个地方有什么好玩的'))]\n",
      "结果: 云南是一个充满魅力的地方，有很多值得一游的景点和活动。\n",
      "\n",
      "1.玉龙雪山：这是云南著名的景点之一，可以乘坐缆车到达山顶，欣赏壮观的雪山风光。\n",
      "\n",
      "2.丽江古城：古朴的建筑、石板路和美丽的风景让人仿佛穿越回古代。\n",
      "\n",
      "3.泸沽湖：这是一个美丽的高原湖泊，可以在湖边散步、划船或者骑行。\n",
      "\n",
      "4.香格里拉：这里有着壮丽的自然风光和独特的藏文化，是探险和徒步旅行的好去处。\n",
      "\n",
      "5.石林：这是一个被列入世界自然遗产的地方，可以欣赏到奇特的石灰岩地貌景观。\n",
      "\n",
      "除此之外，云南还有很多名胜古迹、美食和民俗文化等，让人流连忘返。希望你能在云南旅行中度过愉快的时光！\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "# 提示词模板\n",
    "prompt = ChatPromptTemplate.from_template(\"我想去{topic}旅行，我想知道这个地方有什么好玩的\")\n",
    "\n",
    "# gpt模型\n",
    "model = ChatOpenAI(\n",
    "    openai_api_key=\"\",\n",
    "    openai_api_base=\"\",\n",
    "    temperature=.7\n",
    "                 )\n",
    "\n",
    "# 输出模板\n",
    "print(\"输出模板:\",prompt)\n",
    "\n",
    "# 输出解析器\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "result = chain.invoke({\"topic\": \"云南\"})\n",
    "\n",
    "print(\"结果:\",result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意下面这个代码，它就是LCEL语法将不同的组件拼凑成一个链"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**|** 符号类似于Unix管道操作符，它将不同组件链接在一起，将一个组件的输出作为下一个组件的输入。\n",
    "在这个链条中，用户输入被传递到提示模板，然后提示模板的输出被传递到模型，接着模型的输出被传递到输出解析器。让我们分别看看每个组件，真正理解正在发生的事情。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Prompt\n",
    "**prompt**是一个基础prompt模板，它能接受一个变量  **{topic}**，并生成一个最终**prompt_value**。**prompt_value**是一个包装完成的提示的对象，可以传递给LLM（接受字符串作为输入）或ChatModel（接受消息序列作为输入）。它可以与任何一种语言模型类型一起使用，因为它定义了生成**BaseMessages**和生成字符串的逻辑。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='我想去云南旅行，我想知道这个地方有什么好玩的')])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# promt模板与参数结合\n",
    "prompt_value = prompt.invoke({\"topic\":\"云南\"})\n",
    "prompt_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='我想去云南旅行，我想知道这个地方有什么好玩的')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_value.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: 我想去云南旅行，我想知道这个地方有什么好玩的'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_value.to_string()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Model\n",
    "prompt_value 然后传递给模型。在这种情况下，我们的模型是一个 ChatModel，意味着它将输出一个 BaseMessage。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='云南是中国的一个美丽的省份，有着丰富的自然和人文资源。这里有很多好玩的地方，比如：\\n\\n1. 丽江古城：这是丽江最有名的景点之一，古老的建筑和独特的纳西文化让人流连忘返。\\n\\n2. 玉龙雪山：这座雪山位于丽江市的北部，是中国最南的雪山之一，雄伟壮观。\\n\\n3. 三江并流：这里是金沙江、怒江和澜沧江的交汇处，景色壮丽，令人叹为观止。\\n\\n4. 香格里拉：这是世界上著名的旅游胜地之一，有着壮丽的自然风景和独特的藏传佛教文化。\\n\\n5. 东巴文化村：这是云南著名的民俗文化村，可以了解到东巴文化的传承和发展。\\n\\n除此之外，云南还有很多美丽的自然风景和独特的民族文化，例如玉龙雪山、泸沽湖、西双版纳等等，都是值得一游的地方。希望你在云南旅行愉快！')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = model.invoke(prompt_value)\n",
    "message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.output_parser\n",
    "\n",
    "最后，我们将模型输出传递给output_parser，它是一个BaseOutputParser，意味着它接受字符串或BaseMessage作为输入。StrOutputParser专门将任何输入简单地转换为字符串。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'云南是中国的一个美丽的省份，有着丰富的自然和人文资源。这里有很多好玩的地方，比如：\\n\\n1. 丽江古城：这是丽江最有名的景点之一，古老的建筑和独特的纳西文化让人流连忘返。\\n\\n2. 玉龙雪山：这座雪山位于丽江市的北部，是中国最南的雪山之一，雄伟壮观。\\n\\n3. 三江并流：这里是金沙江、怒江和澜沧江的交汇处，景色壮丽，令人叹为观止。\\n\\n4. 香格里拉：这是世界上著名的旅游胜地之一，有着壮丽的自然风景和独特的藏传佛教文化。\\n\\n5. 东巴文化村：这是云南著名的民俗文化村，可以了解到东巴文化的传承和发展。\\n\\n除此之外，云南还有很多美丽的自然风景和独特的民族文化，例如玉龙雪山、泸沽湖、西双版纳等等，都是值得一游的地方。希望你在云南旅行愉快！'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.invoke(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.完整的Pipeline\n",
    "以下是完整的步骤：\n",
    "  1. 我们以所需主题的用户输入作为 {\"topic\": \"云南\"} 进行传递。\n",
    "  2. 提示组件接受用户输入，然后使用该主题构建提示后生成 prompt_value。\n",
    "  3. 模型组件获取生成的提示，并将其传递给 OpenAI LLM 模型进行回答。模型生成的输出是一个 ChatMessage 对象。\n",
    "  4. 最后，output_parser 组件接收 ChatMessage，并将其转换成 Python 字符串，在调用方法中返回。\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
